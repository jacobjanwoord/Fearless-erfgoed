{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoupNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\used\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\used\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\used\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\used\\AppData\\Local\\Temp\\pip-build-env-51zmi8ax\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\used\\AppData\\Local\\Temp\\pip-build-env-51zmi8ax\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\used\\AppData\\Local\\Temp\\pip-build-env-51zmi8ax\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 487, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\used\\AppData\\Local\\Temp\\pip-build-env-51zmi8ax\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 3\n",
      "          \"You're trying to run a very old release of Beautiful Soup under Python 3. This will not work.\"<>\"Please use Beautiful Soup 4, available through the pip package 'beautifulsoup4'.\"\n",
      "                                                                                                         ^^\n",
      "      SyntaxError: invalid syntax\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "All images have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import urllib.parse\n",
    "url  = \"https://www.dhm.de/datenbank/ccp/prj_dhm_ccp/displayimg.php?laufnrid=cp146161_0&prj_short=dhm_ccp&format=gr&folder=badv\"\n",
    "# url = \"https://www.dhm.de/datenbank/ccp/dhm_ccp.php?seite=6&fld_1=&fld_3=&fld_4=Objektfotos+%28BADV%29&fld_5=Abbildung&fld_6=&fld_6a=&fld_7=&fld_8=&fld_9=&fld_10=&fld_11=&fld_12_a=&fld_12_b=&fld_12a=&fld_13=&suchen=Search\"\n",
    "base_url = \"https://www.dhm.de/datenbank/ccp/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Create a directory to save images\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# Find all image tags\n",
    "img_tags = soup.find_all('img')\n",
    "\n",
    "# Filter valid image URLs\n",
    "def is_valid_image_url(url):\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    return parsed_url.scheme in ['http', 'https'] and parsed_url.path.endswith(('.jpg', '.jpeg', '.png', '.gif'))\n",
    "print(img_tags)\n",
    "# Download and save each image\n",
    "for img in img_tags:\n",
    "    print(img)\n",
    "    img_url = urllib.parse.urljoin(base_url, img['src'])\n",
    "    \n",
    "    if is_valid_image_url(img_url):\n",
    "        img_name = os.path.join('images', os.path.basename(img_url))\n",
    "\n",
    "        img_response = requests.get(img_url)\n",
    "        with open(img_name, 'wb') as file:\n",
    "            file.write(img_response.content)\n",
    "\n",
    "        print(f\"Downloaded {img_name}\")\n",
    "\n",
    "print(\"All images have been downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded images\\cp146161_0.jpg\n",
      "Downloaded images\\cp146162_0.jpg\n",
      "Downloaded images\\cp146163_0.jpg\n",
      "Downloaded images\\cp146164_0.jpg\n",
      "Downloaded images\\cp146165_0.jpg\n",
      "Downloaded images\\cp146166_0.jpg\n",
      "Downloaded images\\cp146167_0.jpg\n",
      "Downloaded images\\cp146168_0.jpg\n",
      "Downloaded images\\cp146169_0.jpg\n",
      "Downloaded images\\cp146170_0.jpg\n",
      "All images have been processed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image, ImageChops\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "base_url = \"https://www.dhm.de/datenbank/ccp/prj_dhm_ccp/displayimg.php?laufnrid=cp{}_0&prj_short=dhm_ccp&format=gr&folder=badv\"\n",
    "start_num = 146161\n",
    "end_num = 146170\n",
    "# no_image_placeholder = 'images/cp146161_0.jpg'\n",
    "no_image_placeholder = None\n",
    "\n",
    "# Create a directory to save images\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "# Download an image from a URL\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "# Check if two images are similar\n",
    "def images_are_similar(img1, img2):\n",
    "    return ImageChops.difference(img1, img2).getbbox() is None\n",
    "\n",
    "# Get and save images\n",
    "for i in range(start_num, end_num + 1):\n",
    "    url = base_url.format(i)\n",
    "    try:\n",
    "        img = download_image(url)\n",
    "        \n",
    "        # Initialize the no_image_placeholder with the first \"no image\" placeholder found\n",
    "        if no_image_placeholder is None and \"no_image\" in url.lower():\n",
    "            no_image_placeholder = img\n",
    "        \n",
    "        if no_image_placeholder and images_are_similar(img, no_image_placeholder):\n",
    "            print(f\"Skipping placeholder image at {url}\")\n",
    "            continue\n",
    "\n",
    "        img_name = os.path.join('images', f'cp{i}_0.jpg')\n",
    "        img.save(img_name)\n",
    "        print(f\"Downloaded {img_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download image from {url}: {e}\")\n",
    "\n",
    "print(\"All images have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dhm.de/datenbank/ccp/prj_dhm_ccp/displayimg.php?laufnrid=cp146161_0&prj_short=dhm_ccp&format=gr&folder=badv\"\n",
    "\n",
    "# def download_image(url):\n",
    "    # response = requests.get(url)\n",
    "    # img = Image.open(BytesIO(response.content))\n",
    "    # return img\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    if response.headers['Content-Type'].startswith('image'):\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "test_image = os.path.join('images', f'test.jpg')\n",
    "img.save(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
