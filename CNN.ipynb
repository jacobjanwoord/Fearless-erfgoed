{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "653a9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd47a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "optional_path = \"Downloads\"\n",
    "relative_path_nk = \"nk_collection_meubels_cleaned\"\n",
    "relative_path_munich = \"scraped_images_grayscaled_big\"\n",
    "abs_path_nk = os.path.join(base_dir, optional_path, relative_path_nk)\n",
    "abs_path_munich = os.path.join(base_dir, optional_path, relative_path_munich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1afd7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.features[0] = nn.Conv2d(1,64,kernel_size=(3,3), stride=(1,1),padding=(1,1))\n",
    "model = nn.Sequential(*[*list(model.children())[:-1][0][:-10]])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    This function takes a path to a single image, it then resizes it to size 50x50 \\\n",
    "    and normalizes it to the range [0,1]. Lastly, it adds an extra dimension to the image \\\n",
    "    which represents the batch size. These steps are needed, because we want to pass the image \\\n",
    "    to a CNN. \n",
    "    \"\"\"\n",
    "    \n",
    "    img = cv2.imread(image_path, -1)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    mask = np.ones(img.shape, np.uint8)\n",
    "    mask.fill(255)\n",
    "    cv2.drawContours(mask, contours, 0, 0, -1)\n",
    "    img = cv2.add(thresh, mask)\n",
    "    kernel = np.ones((5,5), dtype=np.uint8)\n",
    "    img = cv2.erode(img, kernel, 10)\n",
    "    img = np.abs(np.max(img) - img)\n",
    "    \n",
    "    img = cv2.resize(img, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "    preprocess = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    img = preprocess(img).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "def extract_features(image_path):\n",
    "    \"\"\"\n",
    "    This function takes a path to a single image, it then preprocesses the image with the \\\n",
    "    function preprocess_image. Afterwards it passes the image to the pretrained CNN to extract \\\n",
    "    a feature descriptor. \n",
    "    \"\"\"\n",
    "    \n",
    "    img = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        features = model(img)\n",
    "    return features.squeeze(0).numpy()\n",
    "\n",
    "def normalize_features(features):\n",
    "    \"\"\"\n",
    "    This function takes the feature descriptor and normalizes it. This is needed as we want \\\n",
    "    to compute the dot-product similarity between feature descriptors of different images. \\\n",
    "    And for similarity it is convenient to have all pixels on the same scale without too \\\n",
    "    much magnitude differences and this also ensures stability. \n",
    "    \"\"\"\n",
    "    \n",
    "    return features / np.linalg.norm(features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05f6d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_model_state_dict = model.state_dict()\n",
    "#torch.save(best_model_state_dict, \"best2_vgg16_weights.pth\")\n",
    "best_model_state_dict = torch.load(\"best2_vgg16_weights.pth\")\n",
    "model.load_state_dict(best_model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b380a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nk_img = os.path.join(base_dir, optional_path, \"nk_testset\", \"kast_nk.jpg\")\n",
    "munich_imgs = os.listdir(abs_path_munich)\n",
    "\n",
    "def compute_similarities(nk_img, munich_imgs, \n",
    "                         path=abs_path_munich):\n",
    "    \"\"\"\n",
    "    This function takes three arguments: \n",
    "    - nk_img, which is a single image from the nk collection. \n",
    "    - munich_imgs, this contains all images from the Munich Database. \n",
    "    - path, this is the path to the gray scaled Munich Database.\n",
    "    \n",
    "    It then computes the feature descriptor for the nk collection image and all the images in the \\\n",
    "    Munich Database. Afterwards takes the dot-product to get the dot-product similiarity. It then \\\n",
    "    saves the similarity and the two images as key-value pairs in a dictionary. \n",
    "    \"\"\"\n",
    "    \n",
    "    similarities = {}\n",
    "    nk_img_feature_descriptor = normalize_features(extract_features(nk_img).flatten())\n",
    "    for img in munich_imgs:\n",
    "        img_path = os.path.join(path, img)\n",
    "        munich_img_feature_descriptor = normalize_features(extract_features(img_path).flatten())\n",
    "        similarity = np.dot(\n",
    "            nk_img_feature_descriptor,\n",
    "            munich_img_feature_descriptor\n",
    "        )\n",
    "        munich_img_name = img_path[img_path.rfind(\"/\")+1:]\n",
    "        nk_img_name = nk_img[nk_img.rfind(\"/\")+1:]\n",
    "        similarities[(nk_img_name, munich_img_name)] = similarity.item()\n",
    "        \n",
    "    return similarities\n",
    "    \n",
    "sims_complete = compute_similarities(nk_img, munich_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28c44578",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sims_complete' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164880/1553530873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msims_complete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.89\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path_munich\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sims_complete' is not defined"
     ]
    }
   ],
   "source": [
    "filtered = {k:v for k,v in sims_complete.items() if v > 0.89}\n",
    "imgs = os.listdir(abs_path_munich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee3eea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(abs_path_munich, '0640_3818_id=cp132632_linz.jpg'), -1)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a6fcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nk_testset = os.listdir(os.path.join(base_dir, optional_path, \"nk_testset\"))\n",
    "munich_testset = os.listdir(os.path.join(base_dir, optional_path, \"munich_testset\"))\n",
    "\n",
    "def compute_similarities_testsets(munich_testset, nk_testset, \n",
    "                                  munich_path=os.path.join(base_dir, optional_path, \"munich_testset\"), \n",
    "                                  nk_path=os.path.join(base_dir, optional_path, \"nk_testset\")):\n",
    "    \"\"\"\n",
    "    This function takes four arguments: \n",
    "    - munich_testset, which contains 5 grayscaled images from the munich database.\n",
    "    - nk_testset, which contains 5 grayscaled images from the nk collection API.\n",
    "    - munich path, the path to the directory of the munich images. \n",
    "    - nk_path, the path to the directory of the nk images. \n",
    "    \n",
    "    It then computes the feature descriptors for the munich images and all the \\\n",
    "    nk collection images. Afterwards takes the dot-product to get the dot-product similiarity. \n",
    "    It then saves the similarity and the two images as key-value pairs in a dictionary. \n",
    "    \"\"\"\n",
    "    \n",
    "    similarities = {}\n",
    "    for nk_img in nk_testset:\n",
    "        nk_img_path = os.path.join(nk_path, nk_img)\n",
    "        for munich_img in munich_testset:\n",
    "            munich_img_path = os.path.join(munich_path, munich_img)\n",
    "            nk_img_feature_descriptor = normalize_features(extract_features(nk_img_path).flatten())\n",
    "            munich_img_feature_descriptor = normalize_features(extract_features(munich_img_path).flatten())\n",
    "            similarity = np.dot(\n",
    "                nk_img_feature_descriptor,\n",
    "                munich_img_feature_descriptor\n",
    "            )\n",
    "            similarities[(nk_img, munich_img)] = similarity.item()\n",
    "        \n",
    "    return similarities\n",
    "    \n",
    "sims = compute_similarities_testsets(munich_testset, nk_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0498509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stoel_mccp</th>\n",
       "      <th>tafel_mccp</th>\n",
       "      <th>kast_mccp</th>\n",
       "      <th>dressoir_mccp</th>\n",
       "      <th>speeltafel_mccp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kast_nk</th>\n",
       "      <td>0.660421</td>\n",
       "      <td>0.661928</td>\n",
       "      <td>0.853438</td>\n",
       "      <td>0.841007</td>\n",
       "      <td>0.686943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speeltafel_nk</th>\n",
       "      <td>0.548683</td>\n",
       "      <td>0.570109</td>\n",
       "      <td>0.554375</td>\n",
       "      <td>0.545816</td>\n",
       "      <td>0.636547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tafel_nk</th>\n",
       "      <td>0.482328</td>\n",
       "      <td>0.558129</td>\n",
       "      <td>0.517739</td>\n",
       "      <td>0.484007</td>\n",
       "      <td>0.552639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dressoir_nk</th>\n",
       "      <td>0.696720</td>\n",
       "      <td>0.688964</td>\n",
       "      <td>0.709567</td>\n",
       "      <td>0.752601</td>\n",
       "      <td>0.590738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoel_nk</th>\n",
       "      <td>0.778562</td>\n",
       "      <td>0.685584</td>\n",
       "      <td>0.731700</td>\n",
       "      <td>0.749232</td>\n",
       "      <td>0.589983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               stoel_mccp  tafel_mccp  kast_mccp  dressoir_mccp  \\\n",
       "kast_nk          0.660421    0.661928   0.853438       0.841007   \n",
       "speeltafel_nk    0.548683    0.570109   0.554375       0.545816   \n",
       "tafel_nk         0.482328    0.558129   0.517739       0.484007   \n",
       "dressoir_nk      0.696720    0.688964   0.709567       0.752601   \n",
       "stoel_nk         0.778562    0.685584   0.731700       0.749232   \n",
       "\n",
       "               speeltafel_mccp  \n",
       "kast_nk               0.686943  \n",
       "speeltafel_nk         0.636547  \n",
       "tafel_nk              0.552639  \n",
       "dressoir_nk           0.590738  \n",
       "stoel_nk              0.589983  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_table(sims):\n",
    "    \"\"\"\n",
    "    This function takes the output produced by either the compute_similarities \\ \n",
    "    or compute_similarities_testsets function, and returns a pandas dataframe/table \\\n",
    "    and also saves it in excel.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    rows = []\n",
    "\n",
    "    for key, value in sims.items():\n",
    "        if key[0] not in data:\n",
    "            data[key[0]] = []\n",
    "        if key[1] not in rows:\n",
    "            rows.append(key[1])\n",
    "        data[key[0]].append(value)\n",
    "        \n",
    "    data = {key[:key.rfind(\".\")]:value for key, value in data.items()}\n",
    "    rows = [row[:row.rfind(\".\")] for row in rows]\n",
    "        \n",
    "    df = pd.DataFrame(data, index=rows)\n",
    "    #df.to_excel('output.xlsx')\n",
    "    return df.T\n",
    "    \n",
    "get_table(sims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
